<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="edu.coursera.distributed.SparkTest" time="2.201" tests="6" errors="6" skipped="0" failures="0">
  <properties>
    <property name="java.specification.version" value="19"/>
    <property name="sun.cpu.isalist" value="amd64"/>
    <property name="sun.jnu.encoding" value="Cp1252"/>
    <property name="java.class.path" value="C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1\target\test-classes;C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1\target\classes;C:\Users\amirmahdi\.m2\repository\org\apache\maven\plugins\maven-resources-plugin\3.3.1\maven-resources-plugin-3.3.1.jar;C:\Users\amirmahdi\.m2\repository\org\codehaus\plexus\plexus-interpolation\1.26\plexus-interpolation-1.26.jar;C:\Users\amirmahdi\.m2\repository\org\codehaus\plexus\plexus-utils\3.5.1\plexus-utils-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\maven\shared\maven-filtering\3.3.1\maven-filtering-3.3.1.jar;C:\Users\amirmahdi\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\amirmahdi\.m2\repository\org\sonatype\plexus\plexus-build-api\0.0.7\plexus-build-api-0.0.7.jar;C:\Users\amirmahdi\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-lang3\3.12.0\commons-lang3-3.12.0.jar;C:\Users\amirmahdi\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\amirmahdi\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-core_2.12\3.5.1\spark-core_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro\1.11.2\avro-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.14.2\jackson-core-2.14.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro-mapred\1.11.2\avro-mapred-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro-ipc\1.11.2\avro-ipc-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\org\tukaani\xz\1.9\xz-1.9.jar;C:\Users\amirmahdi\.m2\repository\com\twitter\chill_2.12\0.10.0\chill_2.12-0.10.0.jar;C:\Users\amirmahdi\.m2\repository\com\esotericsoftware\kryo-shaded\4.0.2\kryo-shaded-4.0.2.jar;C:\Users\amirmahdi\.m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;C:\Users\amirmahdi\.m2\repository\org\objenesis\objenesis\2.5.1\objenesis-2.5.1.jar;C:\Users\amirmahdi\.m2\repository\com\twitter\chill-java\0.10.0\chill-java-0.10.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\xbean\xbean-asm9-shaded\4.23\xbean-asm9-shaded-4.23.jar;C:\Users\amirmahdi\.m2\repository\org\apache\hadoop\hadoop-client-api\3.3.4\hadoop-client-api-3.3.4.jar;C:\Users\amirmahdi\.m2\repository\org\apache\hadoop\hadoop-client-runtime\3.3.4\hadoop-client-runtime-3.3.4.jar;C:\Users\amirmahdi\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-launcher_2.12\3.5.1\spark-launcher_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-kvstore_2.12\3.5.1\spark-kvstore_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\org\rocksdb\rocksdbjni\8.3.2\rocksdbjni-8.3.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-network-common_2.12\3.5.1\spark-network-common_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\com\google\crypto\tink\tink\1.9.0\tink-1.9.0.jar;C:\Users\amirmahdi\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\amirmahdi\.m2\repository\com\google\protobuf\protobuf-java\3.19.6\protobuf-java-3.19.6.jar;C:\Users\amirmahdi\.m2\repository\joda-time\joda-time\2.12.5\joda-time-2.12.5.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-network-shuffle_2.12\3.5.1\spark-network-shuffle_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-unsafe_2.12\3.5.1\spark-unsafe_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-common-utils_2.12\3.5.1\spark-common-utils_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\jul-to-slf4j\2.0.7\jul-to-slf4j-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\jcl-over-slf4j\2.0.7\jcl-over-slf4j-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-slf4j2-impl\2.20.0\log4j-slf4j2-impl-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-core\2.20.0\log4j-core-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-1.2-api\2.20.0\log4j-1.2-api-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\javax\activation\activation\1.1.1\activation-1.1.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-recipes\2.13.0\curator-recipes-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-framework\2.13.0\curator-framework-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-client\2.13.0\curator-client-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\com\google\guava\guava\16.0.1\guava-16.0.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\amirmahdi\.m2\repository\jakarta\servlet\jakarta.servlet-api\4.0.3\jakarta.servlet-api-4.0.3.jar;C:\Users\amirmahdi\.m2\repository\commons-codec\commons-codec\1.16.0\commons-codec-1.16.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-compress\1.23.0\commons-compress-1.23.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-math3\3.6.1\commons-math3-3.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-text\1.10.0\commons-text-1.10.0.jar;C:\Users\amirmahdi\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-collections4\4.4\commons-collections4-4.4.jar;C:\Users\amirmahdi\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\amirmahdi\.m2\repository\com\ning\compress-lzf\1.1.2\compress-lzf-1.1.2.jar;C:\Users\amirmahdi\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.3\snappy-java-1.1.10.3.jar;C:\Users\amirmahdi\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\amirmahdi\.m2\repository\com\github\luben\zstd-jni\1.5.5-4\zstd-jni-1.5.5-4.jar;C:\Users\amirmahdi\.m2\repository\org\roaringbitmap\RoaringBitmap\0.9.45\RoaringBitmap-0.9.45.jar;C:\Users\amirmahdi\.m2\repository\org\roaringbitmap\shims\0.9.45\shims-0.9.45.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\modules\scala-xml_2.12\2.1.0\scala-xml_2.12-2.1.0.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\scala-library\2.12.18\scala-library-2.12.18.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\scala-reflect\2.12.18\scala-reflect-2.12.18.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-jackson_2.12\3.7.0-M11\json4s-jackson_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-core_2.12\3.7.0-M11\json4s-core_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-ast_2.12\3.7.0-M11\json4s-ast_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-scalap_2.12\3.7.0-M11\json4s-scalap_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-client\2.40\jersey-client-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\ws\rs\jakarta.ws.rs-api\2.1.6\jakarta.ws.rs-api-2.1.6.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\external\jakarta.inject\2.6.1\jakarta.inject-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-common\2.40\jersey-common-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\osgi-resource-locator\1.0.3\osgi-resource-locator-1.0.3.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-server\2.40\jersey-server-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\validation\jakarta.validation-api\2.0.2\jakarta.validation-api-2.0.2.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.40\jersey-container-servlet-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.40\jersey-container-servlet-core-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\inject\jersey-hk2\2.40\jersey-hk2-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-locator\2.6.1\hk2-locator-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.6.1\aopalliance-repackaged-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-api\2.6.1\hk2-api-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-utils\2.6.1\hk2-utils-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\javassist\javassist\3.29.2-GA\javassist-3.29.2-GA.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-all\4.1.96.Final\netty-all-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-buffer\4.1.96.Final\netty-buffer-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec\4.1.96.Final\netty-codec-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-http\4.1.96.Final\netty-codec-http-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-http2\4.1.96.Final\netty-codec-http2-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-socks\4.1.96.Final\netty-codec-socks-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-common\4.1.96.Final\netty-common-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-handler\4.1.96.Final\netty-handler-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.96.Final\netty-transport-native-unix-common-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-handler-proxy\4.1.96.Final\netty-handler-proxy-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-resolver\4.1.96.Final\netty-resolver-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport\4.1.96.Final\netty-transport-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.96.Final\netty-transport-classes-epoll-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-classes-kqueue\4.1.96.Final\netty-transport-classes-kqueue-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-epoll\4.1.96.Final\netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-epoll\4.1.96.Final\netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-kqueue\4.1.96.Final\netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-kqueue\4.1.96.Final\netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar;C:\Users\amirmahdi\.m2\repository\com\clearspring\analytics\stream\2.9.6\stream-2.9.6.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-jvm\4.2.19\metrics-jvm-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-json\4.2.19\metrics-json-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-graphite\4.2.19\metrics-graphite-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-jmx\4.2.19\metrics-jmx-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.12\2.15.2\jackson-module-scala_2.12-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\amirmahdi\.m2\repository\org\apache\ivy\ivy\2.5.1\ivy-2.5.1.jar;C:\Users\amirmahdi\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\amirmahdi\.m2\repository\net\razorvine\pickle\1.3\pickle-1.3.jar;C:\Users\amirmahdi\.m2\repository\net\sf\py4j\py4j\0.10.9.7\py4j-0.10.9.7.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-tags_2.12\3.5.1\spark-tags_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-crypto\1.1.0\commons-crypto-1.1.0.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\slf4j-simple\2.0.7\slf4j-simple-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\slf4j-api\2.0.7\slf4j-api-2.0.7.jar;"/>
    <property name="java.vm.vendor" value="Amazon.com Inc."/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="user.variant" value=""/>
    <property name="java.vendor.url" value="https://aws.amazon.com/corretto/"/>
    <property name="user.timezone" value="Asia/Tehran"/>
    <property name="os.name" value="Windows 10"/>
    <property name="java.vm.specification.version" value="19"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="user.country" value="US"/>
    <property name="sun.boot.library.path" value="C:\Users\amirmahdi\.jdks\corretto-19.0.2\bin"/>
    <property name="sun.java.command" value="C:\Users\amirmahdi\AppData\Local\Temp\surefire9739127204046930994\surefirebooter-20250316005457770_3.jar C:\Users\amirmahdi\AppData\Local\Temp\surefire9739127204046930994 2025-03-16T00-54-57_618-jvmRun1 surefire-20250316005457770_1tmp surefire_0-20250316005457770_2tmp"/>
    <property name="jdk.debug" value="release"/>
    <property name="surefire.test.class.path" value="C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1\target\test-classes;C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1\target\classes;C:\Users\amirmahdi\.m2\repository\org\apache\maven\plugins\maven-resources-plugin\3.3.1\maven-resources-plugin-3.3.1.jar;C:\Users\amirmahdi\.m2\repository\org\codehaus\plexus\plexus-interpolation\1.26\plexus-interpolation-1.26.jar;C:\Users\amirmahdi\.m2\repository\org\codehaus\plexus\plexus-utils\3.5.1\plexus-utils-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\maven\shared\maven-filtering\3.3.1\maven-filtering-3.3.1.jar;C:\Users\amirmahdi\.m2\repository\javax\inject\javax.inject\1\javax.inject-1.jar;C:\Users\amirmahdi\.m2\repository\org\sonatype\plexus\plexus-build-api\0.0.7\plexus-build-api-0.0.7.jar;C:\Users\amirmahdi\.m2\repository\commons-io\commons-io\2.11.0\commons-io-2.11.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-lang3\3.12.0\commons-lang3-3.12.0.jar;C:\Users\amirmahdi\.m2\repository\junit\junit\4.13.2\junit-4.13.2.jar;C:\Users\amirmahdi\.m2\repository\org\hamcrest\hamcrest-core\1.3\hamcrest-core-1.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-core_2.12\3.5.1\spark-core_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro\1.11.2\avro-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.14.2\jackson-core-2.14.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro-mapred\1.11.2\avro-mapred-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\avro\avro-ipc\1.11.2\avro-ipc-1.11.2.jar;C:\Users\amirmahdi\.m2\repository\org\tukaani\xz\1.9\xz-1.9.jar;C:\Users\amirmahdi\.m2\repository\com\twitter\chill_2.12\0.10.0\chill_2.12-0.10.0.jar;C:\Users\amirmahdi\.m2\repository\com\esotericsoftware\kryo-shaded\4.0.2\kryo-shaded-4.0.2.jar;C:\Users\amirmahdi\.m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;C:\Users\amirmahdi\.m2\repository\org\objenesis\objenesis\2.5.1\objenesis-2.5.1.jar;C:\Users\amirmahdi\.m2\repository\com\twitter\chill-java\0.10.0\chill-java-0.10.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\xbean\xbean-asm9-shaded\4.23\xbean-asm9-shaded-4.23.jar;C:\Users\amirmahdi\.m2\repository\org\apache\hadoop\hadoop-client-api\3.3.4\hadoop-client-api-3.3.4.jar;C:\Users\amirmahdi\.m2\repository\org\apache\hadoop\hadoop-client-runtime\3.3.4\hadoop-client-runtime-3.3.4.jar;C:\Users\amirmahdi\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-launcher_2.12\3.5.1\spark-launcher_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-kvstore_2.12\3.5.1\spark-kvstore_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.15.2\jackson-annotations-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\org\rocksdb\rocksdbjni\8.3.2\rocksdbjni-8.3.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-network-common_2.12\3.5.1\spark-network-common_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\com\google\crypto\tink\tink\1.9.0\tink-1.9.0.jar;C:\Users\amirmahdi\.m2\repository\com\google\code\gson\gson\2.10.1\gson-2.10.1.jar;C:\Users\amirmahdi\.m2\repository\com\google\protobuf\protobuf-java\3.19.6\protobuf-java-3.19.6.jar;C:\Users\amirmahdi\.m2\repository\joda-time\joda-time\2.12.5\joda-time-2.12.5.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-network-shuffle_2.12\3.5.1\spark-network-shuffle_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-unsafe_2.12\3.5.1\spark-unsafe_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-common-utils_2.12\3.5.1\spark-common-utils_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\jul-to-slf4j\2.0.7\jul-to-slf4j-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\jcl-over-slf4j\2.0.7\jcl-over-slf4j-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-slf4j2-impl\2.20.0\log4j-slf4j2-impl-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-api\2.20.0\log4j-api-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-core\2.20.0\log4j-core-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\logging\log4j\log4j-1.2-api\2.20.0\log4j-1.2-api-2.20.0.jar;C:\Users\amirmahdi\.m2\repository\javax\activation\activation\1.1.1\activation-1.1.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-recipes\2.13.0\curator-recipes-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-framework\2.13.0\curator-framework-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\curator\curator-client\2.13.0\curator-client-2.13.0.jar;C:\Users\amirmahdi\.m2\repository\com\google\guava\guava\16.0.1\guava-16.0.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\zookeeper\zookeeper\3.6.3\zookeeper-3.6.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\zookeeper\zookeeper-jute\3.6.3\zookeeper-jute-3.6.3.jar;C:\Users\amirmahdi\.m2\repository\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;C:\Users\amirmahdi\.m2\repository\jakarta\servlet\jakarta.servlet-api\4.0.3\jakarta.servlet-api-4.0.3.jar;C:\Users\amirmahdi\.m2\repository\commons-codec\commons-codec\1.16.0\commons-codec-1.16.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-compress\1.23.0\commons-compress-1.23.0.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-math3\3.6.1\commons-math3-3.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-text\1.10.0\commons-text-1.10.0.jar;C:\Users\amirmahdi\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-collections4\4.4\commons-collections4-4.4.jar;C:\Users\amirmahdi\.m2\repository\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;C:\Users\amirmahdi\.m2\repository\com\ning\compress-lzf\1.1.2\compress-lzf-1.1.2.jar;C:\Users\amirmahdi\.m2\repository\org\xerial\snappy\snappy-java\1.1.10.3\snappy-java-1.1.10.3.jar;C:\Users\amirmahdi\.m2\repository\org\lz4\lz4-java\1.8.0\lz4-java-1.8.0.jar;C:\Users\amirmahdi\.m2\repository\com\github\luben\zstd-jni\1.5.5-4\zstd-jni-1.5.5-4.jar;C:\Users\amirmahdi\.m2\repository\org\roaringbitmap\RoaringBitmap\0.9.45\RoaringBitmap-0.9.45.jar;C:\Users\amirmahdi\.m2\repository\org\roaringbitmap\shims\0.9.45\shims-0.9.45.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\modules\scala-xml_2.12\2.1.0\scala-xml_2.12-2.1.0.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\scala-library\2.12.18\scala-library-2.12.18.jar;C:\Users\amirmahdi\.m2\repository\org\scala-lang\scala-reflect\2.12.18\scala-reflect-2.12.18.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-jackson_2.12\3.7.0-M11\json4s-jackson_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-core_2.12\3.7.0-M11\json4s-core_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-ast_2.12\3.7.0-M11\json4s-ast_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\json4s\json4s-scalap_2.12\3.7.0-M11\json4s-scalap_2.12-3.7.0-M11.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-client\2.40\jersey-client-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\ws\rs\jakarta.ws.rs-api\2.1.6\jakarta.ws.rs-api-2.1.6.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\external\jakarta.inject\2.6.1\jakarta.inject-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-common\2.40\jersey-common-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\annotation\jakarta.annotation-api\1.3.5\jakarta.annotation-api-1.3.5.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\osgi-resource-locator\1.0.3\osgi-resource-locator-1.0.3.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\core\jersey-server\2.40\jersey-server-2.40.jar;C:\Users\amirmahdi\.m2\repository\jakarta\validation\jakarta.validation-api\2.0.2\jakarta.validation-api-2.0.2.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet\2.40\jersey-container-servlet-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\containers\jersey-container-servlet-core\2.40\jersey-container-servlet-core-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\jersey\inject\jersey-hk2\2.40\jersey-hk2-2.40.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-locator\2.6.1\hk2-locator-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\external\aopalliance-repackaged\2.6.1\aopalliance-repackaged-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-api\2.6.1\hk2-api-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\glassfish\hk2\hk2-utils\2.6.1\hk2-utils-2.6.1.jar;C:\Users\amirmahdi\.m2\repository\org\javassist\javassist\3.29.2-GA\javassist-3.29.2-GA.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-all\4.1.96.Final\netty-all-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-buffer\4.1.96.Final\netty-buffer-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec\4.1.96.Final\netty-codec-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-http\4.1.96.Final\netty-codec-http-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-http2\4.1.96.Final\netty-codec-http2-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-codec-socks\4.1.96.Final\netty-codec-socks-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-common\4.1.96.Final\netty-common-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-handler\4.1.96.Final\netty-handler-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-unix-common\4.1.96.Final\netty-transport-native-unix-common-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-handler-proxy\4.1.96.Final\netty-handler-proxy-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-resolver\4.1.96.Final\netty-resolver-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport\4.1.96.Final\netty-transport-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-classes-epoll\4.1.96.Final\netty-transport-classes-epoll-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-classes-kqueue\4.1.96.Final\netty-transport-classes-kqueue-4.1.96.Final.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-epoll\4.1.96.Final\netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-epoll\4.1.96.Final\netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-kqueue\4.1.96.Final\netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar;C:\Users\amirmahdi\.m2\repository\io\netty\netty-transport-native-kqueue\4.1.96.Final\netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar;C:\Users\amirmahdi\.m2\repository\com\clearspring\analytics\stream\2.9.6\stream-2.9.6.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-core\4.2.19\metrics-core-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-jvm\4.2.19\metrics-jvm-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-json\4.2.19\metrics-json-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-graphite\4.2.19\metrics-graphite-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\io\dropwizard\metrics\metrics-jmx\4.2.19\metrics-jmx-4.2.19.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.15.2\jackson-databind-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.12\2.15.2\jackson-module-scala_2.12-2.15.2.jar;C:\Users\amirmahdi\.m2\repository\com\thoughtworks\paranamer\paranamer\2.8\paranamer-2.8.jar;C:\Users\amirmahdi\.m2\repository\org\apache\ivy\ivy\2.5.1\ivy-2.5.1.jar;C:\Users\amirmahdi\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\amirmahdi\.m2\repository\net\razorvine\pickle\1.3\pickle-1.3.jar;C:\Users\amirmahdi\.m2\repository\net\sf\py4j\py4j\0.10.9.7\py4j-0.10.9.7.jar;C:\Users\amirmahdi\.m2\repository\org\apache\spark\spark-tags_2.12\3.5.1\spark-tags_2.12-3.5.1.jar;C:\Users\amirmahdi\.m2\repository\org\apache\commons\commons-crypto\1.1.0\commons-crypto-1.1.0.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\slf4j-simple\2.0.7\slf4j-simple-2.0.7.jar;C:\Users\amirmahdi\.m2\repository\org\slf4j\slf4j-api\2.0.7\slf4j-api-2.0.7.jar;"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="C:\Users\amirmahdi"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.version.date" value="2023-01-17"/>
    <property name="java.home" value="C:\Users\amirmahdi\.jdks\corretto-19.0.2"/>
    <property name="file.separator" value="\"/>
    <property name="basedir" value="C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1"/>
    <property name="java.vm.compressedOopsMode" value="Zero based"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="surefire.real.class.path" value="C:\Users\amirmahdi\AppData\Local\Temp\surefire9739127204046930994\surefirebooter-20250316005457770_3.jar"/>
    <property name="user.script" value=""/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="19.0.2+7-FR"/>
    <property name="user.name" value="amirmahdi"/>
    <property name="stdout.encoding" value="Cp1252"/>
    <property name="path.separator" value=";"/>
    <property name="os.version" value="10.0"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="java.vendor.version" value="Corretto-19.0.2.7.1"/>
    <property name="localRepository" value="C:\Users\amirmahdi\.m2\repository"/>
    <property name="java.vendor.url.bug" value="https://github.com/corretto/corretto-19/issues/"/>
    <property name="java.io.tmpdir" value="C:\Users\AMIRMA~1\AppData\Local\Temp\"/>
    <property name="idea.version" value="2021.2.4"/>
    <property name="java.version" value="19.0.2"/>
    <property name="user.dir" value="C:\Users\amirmahdi\Desktop\Coursera_Distributed_Programming\Spark_Page_Rank\miniproject_1"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="sun.os.patch.level" value=""/>
    <property name="native.encoding" value="Cp1252"/>
    <property name="java.library.path" value="C:\Users\amirmahdi\.jdks\corretto-19.0.2\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\Program Files (x86)\GitExtensions\;&quot;C:\MinGW\bin;C:\MinGW\msys\1.0\bin;&quot;;C:\Program Files\Wolfram Research\WolframScript\;C:\Program Files\GitHub CLI\;C:\Program Files\dotnet\;C:\Program Files\PuTTY\;C:\Users\amirmahdi\AppData\Local\Microsoft\WindowsApps;;C:\Users\amirmahdi\AppData\Local\Programs\Microsoft VS Code\bin;."/>
    <property name="java.vm.info" value="mixed mode, sharing"/>
    <property name="stderr.encoding" value="Cp1252"/>
    <property name="java.vendor" value="Amazon.com Inc."/>
    <property name="java.vm.version" value="19.0.2+7-FR"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.class.version" value="63.0"/>
  </properties>
  <testcase name="testIncreasingTwentyThousand" classname="edu.coursera.distributed.SparkTest" time="1.604">
    <error message="class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6" type="java.lang.IllegalAccessError"><![CDATA[java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 20000 websites

SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [org.apache.logging.slf4j.SLF4JServiceProvider@5bd82fed]
SLF4J: Found provider [org.slf4j.simple.SimpleServiceProvider@c1bd0be]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [org.apache.logging.slf4j.SLF4JServiceProvider@5bd82fed]
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/03/16 00:54:59 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:54:59 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:54:59 INFO SparkContext: Java version 19.0.2
25/03/16 00:54:59 WARN Shell: Did not find winutils.exe: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems
25/03/16 00:54:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/03/16 00:54:59 INFO ResourceUtils: ==============================================================
25/03/16 00:54:59 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:54:59 INFO ResourceUtils: ==============================================================
25/03/16 00:54:59 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:54:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/03/16 00:54:59 INFO ResourceProfile: Limiting resource is cpu
25/03/16 00:54:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:54:59 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:54:59 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:54:59 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:54:59 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:54:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:54:59 INFO Utils: Successfully started service 'sparkDriver' on port 55865.
25/03/16 00:54:59 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:54:59 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:54:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:54:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
  <testcase name="testUniformTwentyThousand" classname="edu.coursera.distributed.SparkTest" time="0.11">
    <error message="Could not initialize class org.apache.spark.storage.StorageUtils$" type="java.lang.NoClassDefFoundError"><![CDATA[java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils$
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testUniformTwentyThousand(SparkTest.java:239)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6 [in thread "main"]
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	... 19 more
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 20000 websites

25/03/16 00:54:59 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
java.base/java.lang.reflect.Method.invoke(Method.java:578)
junit.framework.TestCase.runTest(TestCase.java:177)
junit.framework.TestCase.runBare(TestCase.java:142)
junit.framework.TestResult$1.protect(TestResult.java:122)
junit.framework.TestResult.runProtected(TestResult.java:142)
junit.framework.TestResult.run(TestResult.java:125)
junit.framework.TestCase.run(TestCase.java:130)
junit.framework.TestSuite.runTest(TestSuite.java:241)
junit.framework.TestSuite.run(TestSuite.java:236)
org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
25/03/16 00:54:59 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:54:59 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:54:59 INFO SparkContext: Java version 19.0.2
25/03/16 00:54:59 INFO ResourceUtils: ==============================================================
25/03/16 00:54:59 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:54:59 INFO ResourceUtils: ==============================================================
25/03/16 00:54:59 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:54:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:54:59 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:54:59 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:54:59 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:54:59 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:54:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:54:59 INFO Utils: Successfully started service 'sparkDriver' on port 55866.
25/03/16 00:54:59 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:54:59 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:54:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:54:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
  <testcase name="testRandomTwentyThousand" classname="edu.coursera.distributed.SparkTest" time="0.105">
    <error message="Could not initialize class org.apache.spark.storage.StorageUtils$" type="java.lang.NoClassDefFoundError"><![CDATA[java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils$
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testRandomTwentyThousand(SparkTest.java:283)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6 [in thread "main"]
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	... 19 more
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 20000 websites

25/03/16 00:55:00 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
edu.coursera.distributed.SparkTest.testUniformTwentyThousand(SparkTest.java:239)
java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
java.base/java.lang.reflect.Method.invoke(Method.java:578)
junit.framework.TestCase.runTest(TestCase.java:177)
junit.framework.TestCase.runBare(TestCase.java:142)
junit.framework.TestResult$1.protect(TestResult.java:122)
junit.framework.TestResult.runProtected(TestResult.java:142)
junit.framework.TestResult.run(TestResult.java:125)
junit.framework.TestCase.run(TestCase.java:130)
junit.framework.TestSuite.runTest(TestSuite.java:241)
junit.framework.TestSuite.run(TestSuite.java:236)
org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
25/03/16 00:55:00 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:55:00 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:55:00 INFO SparkContext: Java version 19.0.2
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:55:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:55:00 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:55:00 INFO Utils: Successfully started service 'sparkDriver' on port 55867.
25/03/16 00:55:00 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:55:00 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
  <testcase name="testIncreasingFiftyThousand" classname="edu.coursera.distributed.SparkTest" time="0.109">
    <error message="Could not initialize class org.apache.spark.storage.StorageUtils$" type="java.lang.NoClassDefFoundError"><![CDATA[java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils$
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingFiftyThousand(SparkTest.java:272)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6 [in thread "main"]
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	... 19 more
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 50000 websites

25/03/16 00:55:00 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
edu.coursera.distributed.SparkTest.testRandomTwentyThousand(SparkTest.java:283)
java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
java.base/java.lang.reflect.Method.invoke(Method.java:578)
junit.framework.TestCase.runTest(TestCase.java:177)
junit.framework.TestCase.runBare(TestCase.java:142)
junit.framework.TestResult$1.protect(TestResult.java:122)
junit.framework.TestResult.runProtected(TestResult.java:142)
junit.framework.TestResult.run(TestResult.java:125)
junit.framework.TestCase.run(TestCase.java:130)
junit.framework.TestSuite.runTest(TestSuite.java:241)
junit.framework.TestSuite.run(TestSuite.java:236)
org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
25/03/16 00:55:00 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:55:00 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:55:00 INFO SparkContext: Java version 19.0.2
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:55:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:55:00 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:55:00 INFO Utils: Successfully started service 'sparkDriver' on port 55868.
25/03/16 00:55:00 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:55:00 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
  <testcase name="testRandomFiftyThousand" classname="edu.coursera.distributed.SparkTest" time="0.088">
    <error message="Could not initialize class org.apache.spark.storage.StorageUtils$" type="java.lang.NoClassDefFoundError"><![CDATA[java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils$
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testRandomFiftyThousand(SparkTest.java:294)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6 [in thread "main"]
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	... 19 more
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 50000 websites

25/03/16 00:55:00 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
edu.coursera.distributed.SparkTest.testIncreasingFiftyThousand(SparkTest.java:272)
java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
java.base/java.lang.reflect.Method.invoke(Method.java:578)
junit.framework.TestCase.runTest(TestCase.java:177)
junit.framework.TestCase.runBare(TestCase.java:142)
junit.framework.TestResult$1.protect(TestResult.java:122)
junit.framework.TestResult.runProtected(TestResult.java:142)
junit.framework.TestResult.run(TestResult.java:125)
junit.framework.TestCase.run(TestCase.java:130)
junit.framework.TestSuite.runTest(TestSuite.java:241)
junit.framework.TestSuite.run(TestSuite.java:236)
org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
25/03/16 00:55:00 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:55:00 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:55:00 INFO SparkContext: Java version 19.0.2
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:55:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:55:00 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:55:00 INFO Utils: Successfully started service 'sparkDriver' on port 55869.
25/03/16 00:55:00 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:55:00 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
  <testcase name="testUniformFiftyThousand" classname="edu.coursera.distributed.SparkTest" time="0.139">
    <error message="Could not initialize class org.apache.spark.storage.StorageUtils$" type="java.lang.NoClassDefFoundError"><![CDATA[java.lang.NoClassDefFoundError: Could not initialize class org.apache.spark.storage.StorageUtils$
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testUniformFiftyThousand(SparkTest.java:250)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at junit.framework.TestCase.runTest(TestCase.java:177)
	at junit.framework.TestCase.runBare(TestCase.java:142)
	at junit.framework.TestResult$1.protect(TestResult.java:122)
	at junit.framework.TestResult.runProtected(TestResult.java:142)
	at junit.framework.TestResult.run(TestResult.java:125)
	at junit.framework.TestCase.run(TestCase.java:130)
	at junit.framework.TestSuite.runTest(TestSuite.java:241)
	at junit.framework.TestSuite.run(TestSuite.java:236)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:507)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:495)
Caused by: java.lang.ExceptionInInitializerError: Exception java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x25bbe1b6) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x25bbe1b6 [in thread "main"]
	at org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)
	at org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)
	at org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:121)
	at org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:358)
	at org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:295)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:344)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:196)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:284)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:483)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
	at edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
	at edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
	at edu.coursera.distributed.SparkTest.testIncreasingTwentyThousand(SparkTest.java:261)
	... 19 more
]]></error>
    <system-err><![CDATA[Running the PageRank algorithm for 5 iterations on a website graph of 50000 websites

25/03/16 00:55:00 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:
org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
edu.coursera.distributed.SparkTest.getSparkContext(SparkTest.java:38)
edu.coursera.distributed.SparkTest.testDriver(SparkTest.java:170)
edu.coursera.distributed.SparkTest.testRandomFiftyThousand(SparkTest.java:294)
java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
java.base/java.lang.reflect.Method.invoke(Method.java:578)
junit.framework.TestCase.runTest(TestCase.java:177)
junit.framework.TestCase.runBare(TestCase.java:142)
junit.framework.TestResult$1.protect(TestResult.java:122)
junit.framework.TestResult.runProtected(TestResult.java:142)
junit.framework.TestResult.run(TestResult.java:125)
junit.framework.TestCase.run(TestCase.java:130)
junit.framework.TestSuite.runTest(TestSuite.java:241)
junit.framework.TestSuite.run(TestSuite.java:236)
org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:90)
org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:316)
org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:240)
org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:214)
org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:155)
org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:385)
25/03/16 00:55:00 INFO SparkContext: Running Spark version 3.5.1
25/03/16 00:55:00 INFO SparkContext: OS info Windows 10, 10.0, amd64
25/03/16 00:55:00 INFO SparkContext: Java version 19.0.2
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO ResourceUtils: No custom resources configured for spark.driver.
25/03/16 00:55:00 INFO ResourceUtils: ==============================================================
25/03/16 00:55:00 INFO SparkContext: Submitted application: edu.coursera.distributed.PageRank
25/03/16 00:55:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/03/16 00:55:00 INFO SecurityManager: Changing view acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls to: amirmahdi
25/03/16 00:55:00 INFO SecurityManager: Changing view acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: Changing modify acls groups to: 
25/03/16 00:55:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: amirmahdi; groups with view permissions: EMPTY; users with modify permissions: amirmahdi; groups with modify permissions: EMPTY
25/03/16 00:55:00 INFO Utils: Successfully started service 'sparkDriver' on port 55870.
25/03/16 00:55:00 INFO SparkEnv: Registering MapOutputTracker
25/03/16 00:55:00 INFO SparkEnv: Registering BlockManagerMaster
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/03/16 00:55:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
]]></system-err>
  </testcase>
</testsuite>